function [ selected_features ] = cv_feat_selection( tree,cv_mode,input_title  )
%FEATURE SELECTION WITH CROSS_VALIDATION
%   Here we use cross-validation on the Classification Tree as a method to
%   select the most discriminant features, by selecting the features most
%   used in the cross-validation procedure of the classification tree.
%% Preprocess the inputs
start_title = 'Features histogram';
if nargin < 3
    input_title = '';
end

if nargin < 2
    cv_mode = 'kfold';
end

featuresTemp = [];

% Here we repeat the process 100 times to select the features
for n=1:100
    roundFeatsTmp = [];
    % Cross validate the tree
    if strcmp(cv_mode,'leaveout')
        cvTree = crossval(tree,cv_mode,'on');
    else
        cvTree = crossval(tree,cv_mode,10);
    end
    for i=1:size(cvTree.Trained)
        % Extract features from all ten trees generated by cross-validation
        noRepeatRoundFeatsTmp = unique(cvTree.Trained{i}.CutVar);
        roundFeatsTmp = vertcat(roundFeatsTmp,noRepeatRoundFeatsTmp);
    end
    featuresTemp = vertcat(featuresTemp,unique(roundFeatsTmp));
    %featuresTemp = vertcat(featuresTemp,roundFeatsTmp);
end
% Remove empties from keyFeaturesTemp
featuresTemp = featuresTemp(~cellfun('isempty',featuresTemp));

% Converting cell array to numeric array
[m,~] = size(featuresTemp);
features = zeros(m,1);
for i=1:m
    features(i) = str2double(featuresTemp{i});
end

% Plot histogram graph to show the most used features.
figure;
nelements = hist(features,60);
xcenters = (1:1:60);
bar(xcenters,nelements);
title(strcat(start_title,input_title));
xlabel('Caracteristicas');
ylabel('Repetições');
colormap summer
grid on

% Find the features with a threshold
selected_features = find(nelements >= 100 * 0.9);
%selected_features = find(nelements >= max(nelements) * 0.5);

% Clear temp variables
clearvars featuresTemp noRepeatRoundFeatsTmp roundFeatsTmp cvTree ...
    featuresTemp m features figure nelements xcenters
end

